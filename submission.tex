\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage[margin=2cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usepackage[export]{adjustbox}
\usepackage{indentfirst}
\usepackage{wrapfig}
\usepackage{listings}
\usepackage{color}
\usepackage{enumerate}
\usepackage{amssymb, bm}
\usepackage{csvsimple}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{lscape}
\usepackage{amsmath}
\newcommand\tab[1][1cm]{\hspace*{#1}}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstset{ %
    backgroundcolor=\color{gray!10!white},
  basicstyle=\tiny, %footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Python,                 % the language of the code
  morekeywords={*,...},           % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=10pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=1,	                   % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}
\graphicspath{ }
\usetikzlibrary{arrows}

\title{\textbf{COMP0083 Convex Optimisation Assignment}}
%\author{Jian Shu (James) Wu \\ }
\date{Jan 9, 2023}

\begin{document}
\maketitle
\section*{Part 1}
\subsection*{1.1}

The function for (a):

\[\max\{ax+b, x^4-5, e^{x^2}\}\]

is a convex function.

\subsection*{1.2}

For the function:

\[f(x) = \begin{cases}
      -x \tab \text{if } x \in ]-1, 0] \\
      x^2 \tab \text{if } x \geq 0 \\
   \end{cases}\]

the sub-differential is:

\[\partial f(x) = \begin{cases}
      -1 \tab \text{if } x \in ]-1, 0[ \\
      \left[0, 1\right] \tab \text{if } x = 0  \\
      2x \tab \text{if } x > 0 \\
   \end{cases}\]

corresponding to Figure (a).

\subsection*{1.3}
For a function:
\[f(x) = \langle Ax, x \rangle + \langle x, b\rangle + c\]

where A is a square matrix not necessarily symmetric, the gradient is (a):

\[\nabla f(x) = A^*x + Ax + b\]

\subsection*{1.4}

The Fenchel conjugate of $f(x) = g(2x)$ is (a):

\[f^*(u) = g^*(u/2)\]

\subsection*{1.5}

The solution to the dual problem is (c):

\[\bar{u} = (\textbf{K}+\lambda n \textbf{Id})^{-1} y\]

\section*{Part 2}
\subsection*{2.1}


\subsection*{2.1.1}

Given :
\[ f(x) = \begin{cases}
      +\infty \tab \text{if } x \leq 0 \\
      -\log x \tab \text{if } x > 0 \\
   \end{cases}\]

The Fenchel conjugate is defined:

\[f^*(u) = \sup_{x\in \mathcal{X}} \{ \langle x, u\rangle +  \log x \}\]

To find the supremum, we can take the partial derivative with respect to $x$, set to zero, and solve for x:

\[\frac{\partial}{\partial x}(ux + logx) = u + \frac{1}{x} = 0\]

Thus, the supremum above is solved when $x=\frac{-1}{u}$:

\[f^*(u) = u \left(\frac{-1}{u} \right) +  \log\left(\frac{-1}{u} \right) \]

Simplifying, we have the Fenchel conjugate:

\[f^*(u) = - (1 + \log u)\]

\subsection*{2.1.2} Given:

\[f(x) = x^2\]

The Fenchel conjugate is defined:

\[f^*(u) = \sup_{x\in \mathcal{X}} \{ \langle x, u\rangle - x^2 \}\]

We can compute the partial derivative:

\[\frac{\partial}{\partial x}(ux - x^2) = u - 2x = 0\]

Thus, the supremum is solved when $x=\frac{u}{2}$:

\[f^*(u) = u \left(\frac{u}{2} \right) -  \left(\frac{u}{2} \right)^2 \]

Simplifying, we have the Fenchel conjugate:

\[f^*(u) =  \frac{u^2}{4}\]

\subsection*{2.1.3}Given:

\[f(x) = i_{\left[0, 1\right]}\]

The Fenchel conjugate is defined:

\[f^*(u) = \sup_{x\in \mathcal{X}} \{ \langle x, u\rangle - i_{\left[0, 1\right]} \}\]

Thus,

\[f^*(u) = \sup_{x\in \left[0, 1\right]} \{ \langle x, u\rangle \}\]

We can see the Fenchel conjugate is:

%\[ f^*(u) = \begin{cases}
%      0 \tab \text{if } u < 0 \\
%      u \tab \text{if } u \geq 0 \\
%   \end{cases}\]

\[ f^*(u) = \max(0, u)}\]


\subsection*{2.2.1}

Given $f$ a proper convex function, to prove by induction Jensen's inequality:

\[f\left(\sum_{i=1}^n \lambda_i x_i\right) \leq \sum_{i=1}^{n} \lambda_i f(x_i)\]

for all $x_1, ... x_n \in \mathcal{X}$ and for all $\lambda_1, ..., \lambda_n \in \mathbb{R}_+$ with $\sum_{i=1}^n \lambda_i = 1$, we start with the definition of convexity which states:

\[f(\lambda_1 x_1 + \lambda_2 x_2) \leq \lambda_1 f(x_1) + \lambda_2 f(x_2)\]

for all $x1, x2 \in \mathcal{X}$ and $\lambda_1, \lambda_2 \in \mathbb{R}_+$ with $\lambda_1 + \lambda_2 = 1$. In this base case $n=2$.

Our inductive step will prove that the inequality continues to hold for $n+1$:

\[f\left(\sum_{i=1}^{n+1} \lambda_i x_i\right) = f\left(\sum_{i=1}^n \lambda_i x_i + \lambda_{n+1} x_{n+1}\right)\]

We can insert the term $(1-\lambda_{n+1})$:

\[f\left(\sum_{i=1}^{n+1} \lambda_i x_i\right) = f\left((1-\lambda_{n+1}) \sum_{i=1}^n \frac{\lambda_i}{1-\lambda_{n+1}} x_i + \lambda_{n+1} x_{n+1}\right)\]


If we define $\bar{x} = \sum_{i=1}^n \frac{\lambda_i}{1-\lambda_{n+1}} x_i$ and we are back to our $n=2$ base case, so we know from convexity:

\[ f\left((1-\lambda_{n+1})\bar{x} + \lambda_{n+1} x_{n+1}\right) \leq (1-\lambda_{n+1}) f\left( \bar{x}\right) + \lambda_{n+1} f\left( x_{n+1}\right)\]

Rewriting this,

\[f\left(\sum_{i=1}^{n+1} \lambda_i x_i\right) \leq (1-\lambda_{n+1}) f\left( \sum_{i=1}^n \frac{\lambda_i}{1-\lambda_{n+1}} x_i\right) + \lambda_{n+1} f\left( x_{n+1}\right)\]

We know that the first term on the right hand side:

\[f\left( \sum_{i=1}^n \frac{\lambda_i}{1-\lambda_{n+1}} x_i\right) = \frac{1}{{1-\lambda_{n+1}}}f\left( \sum_{i=1}^n \lambda_i x_i\right) \leq \frac{1}{{1-\lambda_{n+1}}} \sum_{i=1}^n \lambda_i f \left(x_i\right) =  \sum_{i=1}^n \frac{\lambda_i}{{1-\lambda_{n+1}}}  f \left(x_i\right)\]

Thus can upper bound our previous inequality:


\[f\left(\sum_{i=1}^{n+1} \lambda_i x_i\right)  \leq \sum_{i=1}^n \frac{\lambda_i}{{1-\lambda_{n+1}}}  f \left(x_i\right) + \lambda_{n+1} f\left( x_{n+1}\right) =\sum_{i=1}^{n+1} \frac{\lambda_i}{{1-\lambda_{n+1}}} f \left(x_i\right) \]

proving our inductive step and Jensen's inequality as required. \square


\subsection*{2.2.2}
The characterisation of convexity states:

\[\text{f is convex} \leftrightarrow \langle \nabla f(x) - \nabla f(y), x-y \rangle \geq 0\]

$\forall x, y \in dom f$.

For $f(x) = -\log(x)$, $\nabla f(x) = \frac{-1}{x}$:

\[\langle \nabla f(x) - \nabla f(y), x-y \rangle = \langle \frac{1}{y}-\frac{1}{x}, x-y \rangle\]

If $x>y$ we have the following:

\begin{gather*}
    \frac{1}{y} > \frac{1}{x}\\
    x-y>0\\
    \frac{1}{y} - \frac{1}{x} > 0\\
\end{gather*}

and
\[\langle \frac{1}{y}-\frac{1}{x}, x-y \rangle > 0\]

If $x<y$ we have the following:
\begin{gather*}
    \frac{1}{y} < \frac{1}{x}\\
    x-y<0\\
    \frac{1}{y} - \frac{1}{x} < 0\\
\end{gather*}

and
\[\langle \frac{1}{y}-\frac{1}{x}, x-y \rangle > 0\]

If $x=y$ we have the following:
\begin{gather*}
    \frac{1}{y} = \frac{1}{x}\\
    x-y=0\\
    \frac{1}{y} - \frac{1}{x} = 0\\
\end{gather*}

and
\[\langle \frac{1}{y}-\frac{1}{x}, x-y \rangle = 0\]

Thus, $\forall x, y \in dom f, \langle \nabla f(x) - \nabla f(y), x-y \rangle \geq 0$ so $f(x) = -\log(x)$ is convex. \square

\subsection*{2.2.3}

Given Jensen's inequality in 2.2.1 for a convex function $f(x)$:

\[f\bigg(\sum_{i=1}^n \lambda_i x_i\bigg) \leq \sum_{i=1}^n \lambda_i f(x_i)\]

and having proved in 2.2.2 that $f(x) = -\log(x)$ is convex, we can write:

\[-\log\bigg(\sum_{i=1}^n \lambda_i x_i\bigg) \leq - \sum_{i=1}^n \lambda_i \log(x_i)\]

Rearranging:

\[\sum_{i=1}^n \lambda_i x_i \geq \exp \bigg(\sum_{i=1}^n \log(x_i^{\lambda_i}) \bigg)\]


Choosing $\lambda_i = \frac{1}{n}$:

\[\frac{1}{n}\sum_{i=1}^n x_i \geq \exp \bigg(\sum_{i=1}^n \log(x_i^{\frac{1}{n}}) \bigg)\]

The sum of logarithms is the logarithm of the products:

\[\frac{1}{n}\sum_{i=1}^n x_i \geq \exp \bigg(\log((x_1 \cdots x_n )^{\frac{1}{n}})\bigg)\]

Thus we get our inequality:

\[\frac{1}{n}\sum_{i=1}^n x_i \geq \sqrt[n]{x_1 \cdots x_n}\] \square
\subsection*{2.3}
\subsection*{2.4}
\subsection*{2.5}
  Conditions for the existence of minimizers: $f$ is closed and coercive.

  Conditions for the uniqueness of minimizers: $f$ is strictly convex.
\subsection*{2.6}

\newpage
\section*{Part 3}



\newpage
\section*{Part 4}

We are given the primal problem:

\[\min_{w \in \mathcal{H}} \frac{\lambda}{n} \sum_{i=1}^{n} (1-y_i \langle w, \Lambda(x_i)\rangle)_{+} + \frac{\lambda}{2}\| w\|^2\]

We can express in the form:

\[\min_{w \in \mathcal{H}} g(w) + f(w)\]

where:

\[g(w) = \frac{\lambda}{n} \sum_{i=1}^{n} (1-y_i \langle w, \Lambda(x_i)\rangle)_{+}\]

and

\[f(w) = \frac{\lambda}{2}\| w\|^2\]

The corresponding dual problem:

\[\min_{\alpha \in \mathbb{R}^n} \frac{1}{2} \langle \mathbf{K}_y \alpha, \alpha \rangle - \langle \textbf{1}_n, \alpha\rangle + \sum_{i=1}^{n} i_{\left[0, \frac{1}{\lambda n}\right]}(\alpha_i)\]


We can express in the form:

\[\min_{\alpha \in \mathbb{R}^n} g^*(\alpha) + f^*(\alpha)\]


\subsection*{4.1}




\end{document}
